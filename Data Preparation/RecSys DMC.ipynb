{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from pandas import DataFrame\n",
    "\n",
    "from fuzzywuzzy import fuzz\n",
    "from fuzzywuzzy import process\n",
    "\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>itemID</th>\n",
       "      <th>title</th>\n",
       "      <th>titleFound</th>\n",
       "      <th>title_thalia</th>\n",
       "      <th>author_raw</th>\n",
       "      <th>author_api</th>\n",
       "      <th>author_thalia</th>\n",
       "      <th>language</th>\n",
       "      <th>language_thalia</th>\n",
       "      <th>collection</th>\n",
       "      <th>...</th>\n",
       "      <th>publisher_raw</th>\n",
       "      <th>publisher_api</th>\n",
       "      <th>publishedDate</th>\n",
       "      <th>description</th>\n",
       "      <th>main topic</th>\n",
       "      <th>subtopics</th>\n",
       "      <th>thumbnail</th>\n",
       "      <th>maturityRating</th>\n",
       "      <th>pageCount</th>\n",
       "      <th>isEbook</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5649</td>\n",
       "      <td>... and the Word became a Story</td>\n",
       "      <td>... and the Word became a Story</td>\n",
       "      <td>and the word became a story</td>\n",
       "      <td>The Author</td>\n",
       "      <td>The Author</td>\n",
       "      <td>the author</td>\n",
       "      <td>en</td>\n",
       "      <td>Englisch</td>\n",
       "      <td>2.0</td>\n",
       "      <td>...</td>\n",
       "      <td>Books on Demand</td>\n",
       "      <td>BoD – Books on Demand</td>\n",
       "      <td>2018-04-17</td>\n",
       "      <td>At the beginning was the Word. And from the Wo...</td>\n",
       "      <td>FL</td>\n",
       "      <td>FL FM FN</td>\n",
       "      <td>http://books.google.com/books/content?id=FrElD...</td>\n",
       "      <td>NOT_MATURE</td>\n",
       "      <td>304.0</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>77497</td>\n",
       "      <td>... EVVAI!</td>\n",
       "      <td>... EVVAI!</td>\n",
       "      <td>evvai</td>\n",
       "      <td>Cristina Polacchini</td>\n",
       "      <td>CRISTINA POLACCHINI</td>\n",
       "      <td>cristina polacchini</td>\n",
       "      <td>it</td>\n",
       "      <td>Italienisch</td>\n",
       "      <td>2.0</td>\n",
       "      <td>...</td>\n",
       "      <td>Lulu.com</td>\n",
       "      <td>Lulu.com</td>\n",
       "      <td>2015-08-01</td>\n",
       "      <td>Amicizia, scuola, amore, alti e bassi, in and ...</td>\n",
       "      <td>YFB</td>\n",
       "      <td></td>\n",
       "      <td>http://books.google.com/books/content?id=lGNgC...</td>\n",
       "      <td>NOT_MATURE</td>\n",
       "      <td>106.0</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>13238</td>\n",
       "      <td>'... then he ate my boy entrancers.'</td>\n",
       "      <td>Then He Ate My Boy Entrancers</td>\n",
       "      <td>then he ate my boy entrancers</td>\n",
       "      <td>Louise Rennison</td>\n",
       "      <td>NaN</td>\n",
       "      <td>louise rennison</td>\n",
       "      <td>un</td>\n",
       "      <td>Englisch</td>\n",
       "      <td>2.0</td>\n",
       "      <td>...</td>\n",
       "      <td>HarperCollins Publishers</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2008</td>\n",
       "      <td>NaN</td>\n",
       "      <td>YFM</td>\n",
       "      <td>4Z GB ACN YFQ</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NOT_MATURE</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>24800</td>\n",
       "      <td>... trägt Jeans und Tennisschuhe</td>\n",
       "      <td>\"... trägt Jeans und Tennisschuhe\"</td>\n",
       "      <td>traegt jeans und tennisschuhe</td>\n",
       "      <td>Frauke Kühn</td>\n",
       "      <td>Frauke Kühn</td>\n",
       "      <td>frauke kuehn</td>\n",
       "      <td>un</td>\n",
       "      <td>Deutsch</td>\n",
       "      <td>2.0</td>\n",
       "      <td>...</td>\n",
       "      <td>Rowohlt Repertoire</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1995</td>\n",
       "      <td>NaN</td>\n",
       "      <td>YFCF</td>\n",
       "      <td>5AN 1DFG 1QBDN YFB YFY YXH YXJ 3MPQX         ...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NOT_MATURE</td>\n",
       "      <td>7.0</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>26966</td>\n",
       "      <td>TRIPION  minaccia dallo spazio</td>\n",
       "      <td>\" TRIPION \" minaccia dallo spazio</td>\n",
       "      <td>tripion  minaccia dallo spazio</td>\n",
       "      <td>Stefano Grimaldi</td>\n",
       "      <td>Stefano Grimaldi</td>\n",
       "      <td>stefano grimaldi</td>\n",
       "      <td>it</td>\n",
       "      <td>Italienisch</td>\n",
       "      <td>2.0</td>\n",
       "      <td>...</td>\n",
       "      <td>Lulu.com</td>\n",
       "      <td>Lulu.com</td>\n",
       "      <td>2014-07-06</td>\n",
       "      <td>IL GENERE UMANO E' DESTINATO A SCOMPARIRE...QU...</td>\n",
       "      <td>FL</td>\n",
       "      <td></td>\n",
       "      <td>http://books.google.com/books/content?id=HuPeB...</td>\n",
       "      <td>NOT_MATURE</td>\n",
       "      <td>58.0</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 21 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "  itemID                                 title  \\\n",
       "0   5649       ... and the Word became a Story   \n",
       "1  77497                            ... EVVAI!   \n",
       "2  13238  '... then he ate my boy entrancers.'   \n",
       "3  24800      ... trägt Jeans und Tennisschuhe   \n",
       "4  26966        TRIPION  minaccia dallo spazio   \n",
       "\n",
       "                           titleFound                     title_thalia  \\\n",
       "0     ... and the Word became a Story      and the word became a story   \n",
       "1                          ... EVVAI!                            evvai   \n",
       "2       Then He Ate My Boy Entrancers    then he ate my boy entrancers   \n",
       "3  \"... trägt Jeans und Tennisschuhe\"    traegt jeans und tennisschuhe   \n",
       "4   \" TRIPION \" minaccia dallo spazio   tripion  minaccia dallo spazio   \n",
       "\n",
       "            author_raw           author_api        author_thalia language  \\\n",
       "0           The Author           The Author           the author       en   \n",
       "1  Cristina Polacchini  CRISTINA POLACCHINI  cristina polacchini       it   \n",
       "2      Louise Rennison                  NaN      louise rennison       un   \n",
       "3          Frauke Kühn          Frauke Kühn         frauke kuehn       un   \n",
       "4     Stefano Grimaldi     Stefano Grimaldi     stefano grimaldi       it   \n",
       "\n",
       "  language_thalia  collection  ...             publisher_raw  \\\n",
       "0        Englisch         2.0  ...           Books on Demand   \n",
       "1     Italienisch         2.0  ...                  Lulu.com   \n",
       "2        Englisch         2.0  ...  HarperCollins Publishers   \n",
       "3         Deutsch         2.0  ...        Rowohlt Repertoire   \n",
       "4     Italienisch         2.0  ...                  Lulu.com   \n",
       "\n",
       "           publisher_api publishedDate  \\\n",
       "0  BoD – Books on Demand    2018-04-17   \n",
       "1               Lulu.com    2015-08-01   \n",
       "2                    NaN          2008   \n",
       "3                    NaN          1995   \n",
       "4               Lulu.com    2014-07-06   \n",
       "\n",
       "                                         description main topic  \\\n",
       "0  At the beginning was the Word. And from the Wo...         FL   \n",
       "1  Amicizia, scuola, amore, alti e bassi, in and ...        YFB   \n",
       "2                                                NaN        YFM   \n",
       "3                                                NaN       YFCF   \n",
       "4  IL GENERE UMANO E' DESTINATO A SCOMPARIRE...QU...         FL   \n",
       "\n",
       "                                           subtopics  \\\n",
       "0              FL FM FN                                \n",
       "1                                                      \n",
       "2        4Z GB ACN YFQ                                 \n",
       "3   5AN 1DFG 1QBDN YFB YFY YXH YXJ 3MPQX         ...   \n",
       "4                                                      \n",
       "\n",
       "                                           thumbnail maturityRating pageCount  \\\n",
       "0  http://books.google.com/books/content?id=FrElD...     NOT_MATURE     304.0   \n",
       "1  http://books.google.com/books/content?id=lGNgC...     NOT_MATURE     106.0   \n",
       "2                                                NaN     NOT_MATURE       NaN   \n",
       "3                                                NaN     NOT_MATURE       7.0   \n",
       "4  http://books.google.com/books/content?id=HuPeB...     NOT_MATURE      58.0   \n",
       "\n",
       "   isEbook  \n",
       "0    False  \n",
       "1    False  \n",
       "2    False  \n",
       "3    False  \n",
       "4    False  \n",
       "\n",
       "[5 rows x 21 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# df_data = pd.read_csv(\"../Dataset/processedDataWithThaliaAdded.csv\", nrows=10000,delimiter='|')\n",
    "df_data = pd.read_csv(\"../Dataset/processedDataWithThaliaAdded.csv\", sep = \"|\")\n",
    "df_data.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\rmaql\\Anaconda3\\lib\\site-packages\\pandas\\core\\frame.py:4317: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  return super().fillna(\n",
      "<ipython-input-3-ab1315b834c8>:4: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_dataset['metadata'] = df_dataset[['main topic','subtopics']].apply(lambda x: ' '.join(x), axis = 1)\n",
      "<ipython-input-3-ab1315b834c8>:8: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_dataset['metadata'] = df_dataset['metadata'].str.replace('|',' ')\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>itemID</th>\n",
       "      <th>title_thalia</th>\n",
       "      <th>author_thalia</th>\n",
       "      <th>publisher_api</th>\n",
       "      <th>main topic</th>\n",
       "      <th>subtopics</th>\n",
       "      <th>metadata</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5649</td>\n",
       "      <td>and the word became a story</td>\n",
       "      <td>the author</td>\n",
       "      <td>BoD – Books on Demand</td>\n",
       "      <td>FL</td>\n",
       "      <td>FL FM FN</td>\n",
       "      <td>FL  FL FM FN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>77497</td>\n",
       "      <td>evvai</td>\n",
       "      <td>cristina polacchini</td>\n",
       "      <td>Lulu.com</td>\n",
       "      <td>YFB</td>\n",
       "      <td></td>\n",
       "      <td>YFB</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>13238</td>\n",
       "      <td>then he ate my boy entrancers</td>\n",
       "      <td>louise rennison</td>\n",
       "      <td></td>\n",
       "      <td>YFM</td>\n",
       "      <td>4Z GB ACN YFQ</td>\n",
       "      <td>YFM  4Z GB ACN YFQ</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>24800</td>\n",
       "      <td>traegt jeans und tennisschuhe</td>\n",
       "      <td>frauke kuehn</td>\n",
       "      <td></td>\n",
       "      <td>YFCF</td>\n",
       "      <td>5AN 1DFG 1QBDN YFB YFY YXH YXJ 3MPQX         ...</td>\n",
       "      <td>YFCF  5AN 1DFG 1QBDN YFB YFY YXH YXJ 3MPQX    ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>26966</td>\n",
       "      <td>tripion  minaccia dallo spazio</td>\n",
       "      <td>stefano grimaldi</td>\n",
       "      <td>Lulu.com</td>\n",
       "      <td>FL</td>\n",
       "      <td></td>\n",
       "      <td>FL</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  itemID                     title_thalia        author_thalia  \\\n",
       "0   5649      and the word became a story           the author   \n",
       "1  77497                            evvai  cristina polacchini   \n",
       "2  13238    then he ate my boy entrancers      louise rennison   \n",
       "3  24800    traegt jeans und tennisschuhe         frauke kuehn   \n",
       "4  26966   tripion  minaccia dallo spazio     stefano grimaldi   \n",
       "\n",
       "           publisher_api main topic  \\\n",
       "0  BoD – Books on Demand         FL   \n",
       "1               Lulu.com        YFB   \n",
       "2                               YFM   \n",
       "3                              YFCF   \n",
       "4               Lulu.com         FL   \n",
       "\n",
       "                                           subtopics  \\\n",
       "0              FL FM FN                                \n",
       "1                                                      \n",
       "2        4Z GB ACN YFQ                                 \n",
       "3   5AN 1DFG 1QBDN YFB YFY YXH YXJ 3MPQX         ...   \n",
       "4                                                      \n",
       "\n",
       "                                            metadata  \n",
       "0          FL  FL FM FN                               \n",
       "1               YFB                                   \n",
       "2   YFM  4Z GB ACN YFQ                                \n",
       "3  YFCF  5AN 1DFG 1QBDN YFB YFY YXH YXJ 3MPQX    ...  \n",
       "4                FL                                   "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_dataset = df_data[['itemID','title_thalia','author_thalia','publisher_api','main topic','subtopics']]\n",
    "df_dataset.fillna(\"\",inplace=True)\n",
    "\n",
    "df_dataset['metadata'] = df_dataset[['main topic','subtopics']].apply(lambda x: ' '.join(x), axis = 1)\n",
    "#df_dataset['metadata2'] = df_dataset[['author_thalia','publisher_api']].apply(lambda x: ' '.join(x), axis = 1)\n",
    "\n",
    "\n",
    "df_dataset['metadata'] = df_dataset['metadata'].str.replace('|',' ')\n",
    "df_dataset.head(5)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "title_thalia\n",
       " and the word became a story                       0\n",
       " evvai                                             1\n",
       " then he ate my boy entrancers                     2\n",
       " traegt jeans und tennisschuhe                     3\n",
       " tripion  minaccia dallo spazio                    4\n",
       "                                               ...  \n",
       "the wonderful adventures of nils               57454\n",
       "too close for comfort                          57455\n",
       "trail of lightning                             57456\n",
       "virals                                         57457\n",
       "warriors dawn of the clans 01 the sun trail    57458\n",
       "Length: 57459, dtype: int64"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "indices =pd.Series(df_dataset.index,index = df_dataset[\"title_thalia\"]).drop_duplicates()\n",
    "indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Recommendations based on Metadata (Topic/Subtopic)\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "tfidf = TfidfVectorizer(stop_words='english')\n",
    "tfidf_matrix = tfidf.fit_transform(df_dataset['metadata'])\n",
    "tfidf_df = pd.DataFrame(tfidf_matrix.toarray(), index=df_dataset.index.tolist())\n",
    "\n",
    "#count2=CountVectorizer(stop_words=\"english\")\n",
    "#count_matrix2= count.fit_transform(df_dataset['metadata'])\n",
    "\n",
    "#count_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "ename": "MemoryError",
     "evalue": "Unable to allocate 24.6 GiB for an array with shape (57459, 57459) and data type float64",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mMemoryError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-6-eff0c5ebd0bc>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;31m# Compute the cosine similarity matrix based on the tfidf_matrix\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 5\u001b[1;33m \u001b[0mcontent_correlation\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlinear_kernel\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtfidf_matrix\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtfidf_matrix\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\pairwise.py\u001b[0m in \u001b[0;36mlinear_kernel\u001b[1;34m(X, Y, dense_output)\u001b[0m\n\u001b[0;32m   1002\u001b[0m     \"\"\"\n\u001b[0;32m   1003\u001b[0m     \u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mY\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcheck_pairwise_arrays\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mY\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1004\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0msafe_sparse_dot\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mY\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mT\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdense_output\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdense_output\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1005\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1006\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\u001b[0m in \u001b[0;36minner_f\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     70\u001b[0m                           FutureWarning)\n\u001b[0;32m     71\u001b[0m         \u001b[0mkwargs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m{\u001b[0m\u001b[0mk\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0marg\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mk\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0marg\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msig\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mparameters\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 72\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     73\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0minner_f\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     74\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\extmath.py\u001b[0m in \u001b[0;36msafe_sparse_dot\u001b[1;34m(a, b, dense_output)\u001b[0m\n\u001b[0;32m    155\u001b[0m     if (sparse.issparse(a) and sparse.issparse(b)\n\u001b[0;32m    156\u001b[0m             and dense_output and hasattr(ret, \"toarray\")):\n\u001b[1;32m--> 157\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mret\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtoarray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    158\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mret\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    159\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\scipy\\sparse\\compressed.py\u001b[0m in \u001b[0;36mtoarray\u001b[1;34m(self, order, out)\u001b[0m\n\u001b[0;32m   1023\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mout\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0morder\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1024\u001b[0m             \u001b[0morder\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_swap\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'cf'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1025\u001b[1;33m         \u001b[0mout\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_process_toarray_args\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0morder\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mout\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1026\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mout\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mflags\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mc_contiguous\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0mout\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mflags\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mf_contiguous\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1027\u001b[0m             \u001b[1;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'Output array must be C or F contiguous'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\scipy\\sparse\\base.py\u001b[0m in \u001b[0;36m_process_toarray_args\u001b[1;34m(self, order, out)\u001b[0m\n\u001b[0;32m   1183\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[0mout\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1184\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1185\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mzeros\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0morder\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0morder\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1186\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1187\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mMemoryError\u001b[0m: Unable to allocate 24.6 GiB for an array with shape (57459, 57459) and data type float64"
     ]
    }
   ],
   "source": [
    "# Import linear_kernel\n",
    "from sklearn.metrics.pairwise import linear_kernel\n",
    "\n",
    "# Compute the cosine similarity matrix based on the tfidf_matrix\n",
    "content_correlation = linear_kernel(tfidf_matrix, tfidf_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Recommendations based on Metadata (Topic/Subtopic)\n",
    "def get_recommendations_topic(title, cosine_sim, method_name):\n",
    "    # Get the index of the movie that matches the title\n",
    "    idx = indices[title]\n",
    "\n",
    "    # Get the pairwise similarity scores of all movies with that movie\n",
    "    sim_scores = list(enumerate(cosine_sim[idx]))\n",
    "\n",
    "    # Sort the movies based on the similarity scores\n",
    "    sim_scores = sorted(sim_scores, key=lambda x: x[1], reverse=True)\n",
    "\n",
    "    # Get the scores of the top 5 most similar movies\n",
    "    sim_scores = sim_scores[1:6]\n",
    "\n",
    "    # Get the movie indices\n",
    "    book_indices = [i[0] for i in sim_scores]\n",
    "\n",
    "    # Get the pred scores\n",
    "    book_pred_score = [i[1] for i in sim_scores]\n",
    "\n",
    "    # Return the top 5 most similar movies\n",
    "    return pd.DataFrame({'itemID': book_indices,'title_thalia': list(df_dataset['title_thalia'].iloc[book_indices].values), 'metadata': list(df_dataset['metadata'].iloc[book_indices].values), method_name: book_pred_score})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>itemID</th>\n",
       "      <th>title_thalia</th>\n",
       "      <th>author_thalia</th>\n",
       "      <th>publisher_api</th>\n",
       "      <th>main topic</th>\n",
       "      <th>subtopics</th>\n",
       "      <th>metadata</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5649</td>\n",
       "      <td>and the word became a story</td>\n",
       "      <td>the author</td>\n",
       "      <td>BoD – Books on Demand</td>\n",
       "      <td>FL</td>\n",
       "      <td>FL FM FN</td>\n",
       "      <td>FL  FL FM FN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>77497</td>\n",
       "      <td>evvai</td>\n",
       "      <td>cristina polacchini</td>\n",
       "      <td>Lulu.com</td>\n",
       "      <td>YFB</td>\n",
       "      <td></td>\n",
       "      <td>YFB</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>13238</td>\n",
       "      <td>then he ate my boy entrancers</td>\n",
       "      <td>louise rennison</td>\n",
       "      <td></td>\n",
       "      <td>YFM</td>\n",
       "      <td>4Z GB ACN YFQ</td>\n",
       "      <td>YFM  4Z GB ACN YFQ</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>24800</td>\n",
       "      <td>traegt jeans und tennisschuhe</td>\n",
       "      <td>frauke kuehn</td>\n",
       "      <td></td>\n",
       "      <td>YFCF</td>\n",
       "      <td>5AN 1DFG 1QBDN YFB YFY YXH YXJ 3MPQX         ...</td>\n",
       "      <td>YFCF  5AN 1DFG 1QBDN YFB YFY YXH YXJ 3MPQX    ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>26966</td>\n",
       "      <td>tripion  minaccia dallo spazio</td>\n",
       "      <td>stefano grimaldi</td>\n",
       "      <td>Lulu.com</td>\n",
       "      <td>FL</td>\n",
       "      <td></td>\n",
       "      <td>FL</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>4795</td>\n",
       "      <td>13 chilling tales</td>\n",
       "      <td>edwin f becker</td>\n",
       "      <td>AuthorHouse</td>\n",
       "      <td>DNT</td>\n",
       "      <td>FM</td>\n",
       "      <td>DNT  FM</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>31462</td>\n",
       "      <td>13 gifts a wish novel</td>\n",
       "      <td>wendy mass</td>\n",
       "      <td>Scholastic Paperbacks</td>\n",
       "      <td>YFH</td>\n",
       "      <td></td>\n",
       "      <td>YFH</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>60335|69287|55553</td>\n",
       "      <td>13 kings</td>\n",
       "      <td>v s nesby, vs nesby</td>\n",
       "      <td>Xlibris Corporation</td>\n",
       "      <td>FL</td>\n",
       "      <td></td>\n",
       "      <td>FL</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>45341</td>\n",
       "      <td>13 little blue envelopes epic reads edition</td>\n",
       "      <td>maureen johnson</td>\n",
       "      <td>Katherine Tegen Books</td>\n",
       "      <td>YF</td>\n",
       "      <td>YX</td>\n",
       "      <td>YF  YX</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>47470</td>\n",
       "      <td>13 racconti</td>\n",
       "      <td>vincenzo montevecchi</td>\n",
       "      <td>Lulu.com</td>\n",
       "      <td>FL</td>\n",
       "      <td></td>\n",
       "      <td>FL</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100 rows × 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "               itemID                                 title_thalia  \\\n",
       "0                5649                  and the word became a story   \n",
       "1               77497                                        evvai   \n",
       "2               13238                then he ate my boy entrancers   \n",
       "3               24800                traegt jeans und tennisschuhe   \n",
       "4               26966               tripion  minaccia dallo spazio   \n",
       "..                ...                                          ...   \n",
       "95               4795                            13 chilling tales   \n",
       "96              31462                        13 gifts a wish novel   \n",
       "97  60335|69287|55553                                     13 kings   \n",
       "98              45341  13 little blue envelopes epic reads edition   \n",
       "99              47470                                  13 racconti   \n",
       "\n",
       "           author_thalia          publisher_api main topic  \\\n",
       "0             the author  BoD – Books on Demand         FL   \n",
       "1    cristina polacchini               Lulu.com        YFB   \n",
       "2        louise rennison                               YFM   \n",
       "3           frauke kuehn                              YFCF   \n",
       "4       stefano grimaldi               Lulu.com         FL   \n",
       "..                   ...                    ...        ...   \n",
       "95        edwin f becker            AuthorHouse        DNT   \n",
       "96            wendy mass  Scholastic Paperbacks        YFH   \n",
       "97   v s nesby, vs nesby    Xlibris Corporation         FL   \n",
       "98       maureen johnson  Katherine Tegen Books         YF   \n",
       "99  vincenzo montevecchi               Lulu.com         FL   \n",
       "\n",
       "                                            subtopics  \\\n",
       "0               FL FM FN                                \n",
       "1                                                       \n",
       "2         4Z GB ACN YFQ                                 \n",
       "3    5AN 1DFG 1QBDN YFB YFY YXH YXJ 3MPQX         ...   \n",
       "4                                                       \n",
       "..                                                ...   \n",
       "95                  FM                                  \n",
       "96                                                      \n",
       "97                                                      \n",
       "98                  YX                                  \n",
       "99                                                      \n",
       "\n",
       "                                             metadata  \n",
       "0           FL  FL FM FN                               \n",
       "1                YFB                                   \n",
       "2    YFM  4Z GB ACN YFQ                                \n",
       "3   YFCF  5AN 1DFG 1QBDN YFB YFY YXH YXJ 3MPQX    ...  \n",
       "4                 FL                                   \n",
       "..                                                ...  \n",
       "95             DNT  FM                                 \n",
       "96               YFH                                   \n",
       "97                FL                                   \n",
       "98              YF  YX                                 \n",
       "99                FL                                   \n",
       "\n",
       "[100 rows x 7 columns]"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>itemID</th>\n",
       "      <th>title_thalia</th>\n",
       "      <th>author_thalia</th>\n",
       "      <th>publisher_api</th>\n",
       "      <th>main topic</th>\n",
       "      <th>subtopics</th>\n",
       "      <th>metadata</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [itemID, title_thalia, author_thalia, publisher_api, main topic, subtopics, metadata]\n",
       "Index: []"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "book_search = 'kings'\n",
    "display(df_dataset[df_dataset['title_thalia']==book_search])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>itemID</th>\n",
       "      <th>title_thalia</th>\n",
       "      <th>author_thalia</th>\n",
       "      <th>publisher_api</th>\n",
       "      <th>main topic</th>\n",
       "      <th>subtopics</th>\n",
       "      <th>metadata</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [itemID, title_thalia, author_thalia, publisher_api, main topic, subtopics, metadata]\n",
       "Index: []"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "KeyError",
     "evalue": "'evvai'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\pandas\\core\\indexes\\base.py\u001b[0m in \u001b[0;36mget_loc\u001b[1;34m(self, key, method, tolerance)\u001b[0m\n\u001b[0;32m   2894\u001b[0m             \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2895\u001b[1;33m                 \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcasted_key\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2896\u001b[0m             \u001b[1;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0merr\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mpandas\\_libs\\index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mpandas\\_libs\\index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mpandas\\_libs\\hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mpandas\\_libs\\hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;31mKeyError\u001b[0m: 'evvai'",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-20-53e11ed2758d>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[0mbook_search\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m'evvai'\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[0mdisplay\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdf_dataset\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mdf_dataset\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtitle_thalia\u001b[0m\u001b[1;33m==\u001b[0m\u001b[0mbook_search\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m \u001b[0mget_recommendations_topic\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"evvai\"\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mcontent_correlation\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'Predicted Rating'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m<ipython-input-15-b18886168c27>\u001b[0m in \u001b[0;36mget_recommendations_topic\u001b[1;34m(title, cosine_sim, method_name)\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0mget_recommendations_topic\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtitle\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcosine_sim\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmethod_name\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m     \u001b[1;31m# Get the index of the movie that matches the title\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 4\u001b[1;33m     \u001b[0midx\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mindices\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mtitle\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      5\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      6\u001b[0m     \u001b[1;31m# Get the pairwise similarity scores of all movies with that movie\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\pandas\\core\\series.py\u001b[0m in \u001b[0;36m__getitem__\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m    880\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    881\u001b[0m         \u001b[1;32melif\u001b[0m \u001b[0mkey_is_scalar\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 882\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_get_value\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    883\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    884\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mis_hashable\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\pandas\\core\\series.py\u001b[0m in \u001b[0;36m_get_value\u001b[1;34m(self, label, takeable)\u001b[0m\n\u001b[0;32m    987\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    988\u001b[0m         \u001b[1;31m# Similar to Index.get_value, but we do not fall back to positional\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 989\u001b[1;33m         \u001b[0mloc\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mindex\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlabel\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    990\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mindex\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_get_values_for_loc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mloc\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlabel\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    991\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\pandas\\core\\indexes\\base.py\u001b[0m in \u001b[0;36mget_loc\u001b[1;34m(self, key, method, tolerance)\u001b[0m\n\u001b[0;32m   2895\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcasted_key\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2896\u001b[0m             \u001b[1;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0merr\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2897\u001b[1;33m                 \u001b[1;32mraise\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0merr\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2898\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2899\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mtolerance\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyError\u001b[0m: 'evvai'"
     ]
    }
   ],
   "source": [
    "book_search = 'evvai'\n",
    "display(df_dataset[df_dataset.title_thalia==book_search])\n",
    "get_recommendations_topic(\"evvai\",content_correlation, 'Predicted Rating')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Recommendations Based of Author\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "tfidf = TfidfVectorizer(stop_words='english')\n",
    "tfidf_matrix2 = tfidf.fit_transform(df_dataset['author_thalia'])\n",
    "tfidf_df2 = pd.DataFrame(tfidf_matrix.toarray(), index=df_dataset.index.tolist())\n",
    "\n",
    "#count2=CountVectorizer(stop_words=\"english\")\n",
    "#count_matrix2= count.fit_transform(df_dataset['metadata'])\n",
    "\n",
    "#count_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics.pairwise import linear_kernel\n",
    "\n",
    "# Compute the cosine similarity matrix based on the tfidf_matrix\n",
    "content_correlation2 = linear_kernel(tfidf_matrix2, tfidf_matrix2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Recommendations based on Author\n",
    "def get_recommendations_author(title, cosine_sim, method_name):\n",
    "    # Get the index of the movie that matches the title\n",
    "    idx = indices[title]\n",
    "\n",
    "    # Get the pairwise similarity scores of all movies with that movie\n",
    "    sim_scores = list(enumerate(cosine_sim[idx]))\n",
    "\n",
    "    # Sort the movies based on the similarity scores\n",
    "    sim_scores = sorted(sim_scores, key=lambda x: x[1], reverse=True)\n",
    "\n",
    "    # Get the scores of the top 5 most similar movies\n",
    "    sim_scores = sim_scores[1:6]\n",
    "\n",
    "    # Get the movie indices\n",
    "    book_indices = [i[0] for i in sim_scores]\n",
    "\n",
    "    # Get the pred scores\n",
    "    book_pred_score = [i[1] for i in sim_scores]\n",
    "\n",
    "    return pd.DataFrame({'itemID': book_indices,'title_thalia': list(df_dataset['title_thalia'].iloc[book_indices].values), 'author_thalia': list(df_dataset['author_thalia'].iloc[book_indices].values), method_name: book_pred_score})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>itemID</th>\n",
       "      <th>title_thalia</th>\n",
       "      <th>author_thalia</th>\n",
       "      <th>publisher_api</th>\n",
       "      <th>main topic</th>\n",
       "      <th>subtopics</th>\n",
       "      <th>metadata</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>32836</td>\n",
       "      <td>famous</td>\n",
       "      <td>jilly gagnon, todd strasser</td>\n",
       "      <td>Planet!</td>\n",
       "      <td>YFM</td>\n",
       "      <td>YXQ</td>\n",
       "      <td>YFM  YXQ</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  itemID title_thalia                author_thalia publisher_api main topic  \\\n",
       "1  32836       famous  jilly gagnon, todd strasser       Planet!        YFM   \n",
       "\n",
       "                             subtopics  \\\n",
       "1   YXQ                                  \n",
       "\n",
       "                                  metadata  \n",
       "1  YFM  YXQ                                 "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>itemID</th>\n",
       "      <th>title_thalia</th>\n",
       "      <th>author_thalia</th>\n",
       "      <th>Predicted Rating</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5386</td>\n",
       "      <td>blood on my hands</td>\n",
       "      <td>todd strasser</td>\n",
       "      <td>0.663472</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>6420</td>\n",
       "      <td>cant get there from here</td>\n",
       "      <td>todd strasser</td>\n",
       "      <td>0.663472</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>9953</td>\n",
       "      <td>date with a rockstar</td>\n",
       "      <td>sarah gagnon</td>\n",
       "      <td>0.432974</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4668</td>\n",
       "      <td>belle and moozie and whatshisname</td>\n",
       "      <td>gayle strasser</td>\n",
       "      <td>0.349040</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>8281</td>\n",
       "      <td>cuenta la historia de la quiropráctica</td>\n",
       "      <td>todd waters</td>\n",
       "      <td>0.307443</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   itemID                            title_thalia   author_thalia  \\\n",
       "0    5386                       blood on my hands   todd strasser   \n",
       "1    6420                cant get there from here   todd strasser   \n",
       "2    9953                    date with a rockstar    sarah gagnon   \n",
       "3    4668       belle and moozie and whatshisname  gayle strasser   \n",
       "4    8281  cuenta la historia de la quiropráctica     todd waters   \n",
       "\n",
       "   Predicted Rating  \n",
       "0          0.663472  \n",
       "1          0.663472  \n",
       "2          0.432974  \n",
       "3          0.349040  \n",
       "4          0.307443  "
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "book_search = 'famous'\n",
    "display(df_dataset[df_dataset.title_thalia==book_search])\n",
    "get_recommendations_author(book_search,content_correlation2, 'Predicted Rating')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Recommendations Based of Publisher\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "tfidf = TfidfVectorizer(stop_words='english')\n",
    "tfidf_matrix3 = tfidf.fit_transform(df_dataset['publisher_api'])\n",
    "tfidf_df3 = pd.DataFrame(tfidf_matrix.toarray(), index=df_dataset.index.tolist())\n",
    "\n",
    "#count2=CountVectorizer(stop_words=\"english\")\n",
    "#count_matrix2= count.fit_transform(df_dataset['metadata'])\n",
    "\n",
    "#count_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics.pairwise import linear_kernel\n",
    "\n",
    "# Compute the cosine similarity matrix based on the tfidf_matrix\n",
    "content_correlation3 = linear_kernel(tfidf_matrix3, tfidf_matrix3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_recommendations_publisher(title, cosine_sim, method_name):\n",
    "    # Get the index of the movie that matches the title\n",
    "    idx = indices[title]\n",
    "\n",
    "    # Get the pairwise similarity scores of all movies with that movie\n",
    "    sim_scores = list(enumerate(cosine_sim[idx]))\n",
    "\n",
    "    # Sort the movies based on the similarity scores\n",
    "    sim_scores = sorted(sim_scores, key=lambda x: x[1], reverse=True)\n",
    "\n",
    "    # Get the scores of the top 5 most similar movies\n",
    "    sim_scores = sim_scores[1:6]\n",
    "\n",
    "    # Get the movie indices\n",
    "    book_indices = [i[0] for i in sim_scores]\n",
    "\n",
    "    # Get the pred scores\n",
    "    book_pred_score = [i[1] for i in sim_scores]\n",
    "\n",
    "    return pd.DataFrame({'itemID': book_indices,'title_thalia': list(df_dataset['title_thalia'].iloc[book_indices].values), 'publisher_api': list(df_dataset['publisher_api'].iloc[book_indices].values), method_name: book_pred_score})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>itemID</th>\n",
       "      <th>title_thalia</th>\n",
       "      <th>author_thalia</th>\n",
       "      <th>publisher_api</th>\n",
       "      <th>main topic</th>\n",
       "      <th>subtopics</th>\n",
       "      <th>metadata</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>32836</td>\n",
       "      <td>famous</td>\n",
       "      <td>jilly gagnon, todd strasser</td>\n",
       "      <td>Planet!</td>\n",
       "      <td>YFM</td>\n",
       "      <td>YXQ</td>\n",
       "      <td>YFM  YXQ</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  itemID title_thalia                author_thalia publisher_api main topic  \\\n",
       "1  32836       famous  jilly gagnon, todd strasser       Planet!        YFM   \n",
       "\n",
       "                             subtopics  \\\n",
       "1   YXQ                                  \n",
       "\n",
       "                                  metadata  \n",
       "1  YFM  YXQ                                 "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>itemID</th>\n",
       "      <th>title_thalia</th>\n",
       "      <th>publisher_api</th>\n",
       "      <th>Predicted Rating</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>6236</td>\n",
       "      <td>cappuccetto rosso</td>\n",
       "      <td>The Planet</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>tripion  minaccia dallo spazio</td>\n",
       "      <td>Lulu.com</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>grounded at fort irwin</td>\n",
       "      <td>Xlibris Corporation</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>its not ok</td>\n",
       "      <td>Xlibris Corporation</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>then he ate my boy entrancers</td>\n",
       "      <td></td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   itemID                     title_thalia        publisher_api  \\\n",
       "0    6236                cappuccetto rosso           The Planet   \n",
       "1       0   tripion  minaccia dallo spazio             Lulu.com   \n",
       "2       2           grounded at fort irwin  Xlibris Corporation   \n",
       "3       3                       its not ok  Xlibris Corporation   \n",
       "4       4    then he ate my boy entrancers                        \n",
       "\n",
       "   Predicted Rating  \n",
       "0               1.0  \n",
       "1               0.0  \n",
       "2               0.0  \n",
       "3               0.0  \n",
       "4               0.0  "
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "book_search = 'famous'\n",
    "display(df_dataset[df_dataset.title_thalia==book_search])\n",
    "get_recommendations_publisher(book_search,content_correlation3, 'Predicted Rating')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}

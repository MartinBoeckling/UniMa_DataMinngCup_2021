{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## BPR \n",
    "### https://github.com/manohar029/Ecommerce-Implicit-Data-Recommender-System\n",
    "### http://ethen8181.github.io/machine-learning/recsys/4_bpr.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from pandas import DataFrame\n",
    "\n",
    "\n",
    "from sklearn.metrics import mean_squared_error\n",
    "import matplotlib.pyplot as plt\n",
    "from math import sqrt\n",
    "\n",
    "from numpy.random import randint\n",
    "import implicit\n",
    "import scipy.sparse as sparse\n",
    "import ml_metrics as metrics\n",
    "\n",
    "from scipy.sparse import csr_matrix\n",
    "from scipy.sparse import dok_matrix\n",
    "import math\n",
    "from tqdm import trange\n",
    "from tqdm import tqdm\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "from itertools import islice\n",
    "from sklearn.metrics import roc_auc_score\n",
    "# from sklearn.preprocessing import Normalizer\n",
    "from sklearn import preprocessing\n",
    "from sklearn.neighbors import NearestNeighbors\n",
    "\n",
    "df = pd.read_csv(\"../Dataset/transactionWithRating.csv\", sep=\"|\")\n",
    "# book = pd.read_csv(\"../Dataset/book.csv\", sep=\"|\")\n",
    "\n",
    "# processed1 = pd.read_csv(\"../Dataset/processedDataWithThaliaAddedWithTranslatedTopics.csv\")\n",
    "# processed2 = pd.read_csv(\"../Dataset/processedDataForRemainedPart.csv\", sep=\"|\")\n",
    "# processed1 = processed1.drop([\"Unnamed: 0\"], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(362381, 14)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sessionID</th>\n",
       "      <th>ID_transaction</th>\n",
       "      <th>ID_processed</th>\n",
       "      <th>click</th>\n",
       "      <th>basket</th>\n",
       "      <th>order</th>\n",
       "      <th>title_book</th>\n",
       "      <th>author_book</th>\n",
       "      <th>click_bin</th>\n",
       "      <th>basket_bin</th>\n",
       "      <th>order_bin</th>\n",
       "      <th>rating_ex1</th>\n",
       "      <th>rating_ex2</th>\n",
       "      <th>rating_ex3</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>21310</td>\n",
       "      <td>21310</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Princess Poppy: The Big Mix Up</td>\n",
       "      <td>Janey Louise Jones</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.25</td>\n",
       "      <td>1</td>\n",
       "      <td>0.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>73018</td>\n",
       "      <td>73018</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Einfach zeichnen! Step by Step</td>\n",
       "      <td>Wiebke Krabbe</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.25</td>\n",
       "      <td>1</td>\n",
       "      <td>0.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>19194</td>\n",
       "      <td>19194|1878</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Red Queen 1</td>\n",
       "      <td>Victoria Aveyard</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.25</td>\n",
       "      <td>1</td>\n",
       "      <td>0.5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   sessionID  ID_transaction ID_processed  click  basket  order  \\\n",
       "0          0           21310        21310      1       0      0   \n",
       "1          1           73018        73018      1       0      0   \n",
       "2          2           19194   19194|1878      1       0      0   \n",
       "\n",
       "                       title_book         author_book  click_bin  basket_bin  \\\n",
       "0  Princess Poppy: The Big Mix Up  Janey Louise Jones          1           0   \n",
       "1  Einfach zeichnen! Step by Step       Wiebke Krabbe          1           0   \n",
       "2                     Red Queen 1    Victoria Aveyard          1           0   \n",
       "\n",
       "   order_bin  rating_ex1  rating_ex2  rating_ex3  \n",
       "0          0        0.25           1         0.5  \n",
       "1          0        0.25           1         0.5  \n",
       "2          0        0.25           1         0.5  "
      ]
     },
     "execution_count": 126,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(df.shape)\n",
    "df.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:>"
      ]
     },
     "execution_count": 127,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 864x504 with 3 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig, ax = plt.subplots(1, 3, sharex='col', sharey='row', figsize=(12,7))\n",
    "ax = ax.ravel()\n",
    "\n",
    "df['rating_ex1'].hist(ax=ax[0])\n",
    "df['rating_ex2'].hist(ax=ax[1])\n",
    "df['rating_ex3'].hist(ax=ax[2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df[:1000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count    1000.000000\n",
       "mean        1.100000\n",
       "std         0.567734\n",
       "min         0.000000\n",
       "25%         1.000000\n",
       "50%         1.000000\n",
       "75%         1.000000\n",
       "max         5.000000\n",
       "Name: rating_ex2, dtype: float64"
      ]
     },
     "execution_count": 129,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['rating_ex2'].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0      0.5\n",
       "1      0.5\n",
       "2      0.5\n",
       "3      0.5\n",
       "4      0.5\n",
       "      ... \n",
       "995    0.5\n",
       "996    0.5\n",
       "997    0.5\n",
       "998    0.5\n",
       "999    0.5\n",
       "Name: rating_ex3, Length: 1000, dtype: float64"
      ]
     },
     "execution_count": 130,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['rating_ex3']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_matrix(data, users_col, items_col, ratings_col, threshold = None):\n",
    "    \"\"\"\n",
    "    creates the sparse user-item interaction matrix,\n",
    "    if the data is not in the format where the interaction only\n",
    "    contains the positive items (indicated by 1), then use the \n",
    "    threshold parameter to determine which items are considered positive\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    data : DataFrame\n",
    "        implicit rating data\n",
    "\n",
    "    users_col : str\n",
    "        user column name\n",
    "\n",
    "    items_col : str\n",
    "        item column name\n",
    "    \n",
    "    ratings_col : str\n",
    "        implicit rating column name\n",
    "\n",
    "    threshold : int, default None\n",
    "        threshold to determine whether the user-item pair is \n",
    "        a positive feedback\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    ratings : scipy sparse csr_matrix, shape [n_users, n_items]\n",
    "        user/item ratings matrix\n",
    "\n",
    "    data : DataFrame\n",
    "        implict rating data that retains only the positive feedback\n",
    "        (if specified to do so)\n",
    "    \"\"\"\n",
    "    if threshold is not None:\n",
    "        data = data[data[ratings_col] >= threshold]\n",
    "        data[ratings_col] = 1\n",
    "    \n",
    "    for col in (items_col, users_col, ratings_col):\n",
    "        data[col] = data[col].astype('category')\n",
    "\n",
    "    ratings = csr_matrix((data[ratings_col],\n",
    "                          (data[users_col].cat.codes, data[items_col].cat.codes)))\n",
    "    ratings.eliminate_zeros()\n",
    "    return ratings, data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<786x726 sparse matrix of type '<class 'numpy.int64'>'\n",
       "\twith 961 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 132,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "items_col = 'sessionID'\n",
    "users_col = 'ID_processed'\n",
    "ratings_col = 'rating_ex2'\n",
    "threshold = 0.3\n",
    "X, df = create_matrix(df, users_col, items_col, ratings_col, threshold)\n",
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_train_test(ratings, test_size = 0.2, seed = 1234):\n",
    "    \"\"\"\n",
    "    split the user-item interactions matrix into train and test set\n",
    "    by removing some of the interactions from every user and pretend\n",
    "    that we never seen them\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    ratings : scipy sparse csr_matrix, shape [n_users, n_items]\n",
    "        The user-item interactions matrix\n",
    "    \n",
    "    test_size : float between 0.0 and 1.0, default 0.2\n",
    "        Proportion of the user-item interactions for each user\n",
    "        in the dataset to move to the test set; e.g. if set to 0.2\n",
    "        and a user has 10 interactions, then 2 will be moved to the\n",
    "        test set\n",
    "    \n",
    "    seed : int, default 1234\n",
    "        Seed for reproducible random splitting the \n",
    "        data into train/test set\n",
    "    \n",
    "    Returns\n",
    "    ------- \n",
    "    train : scipy sparse csr_matrix, shape [n_users, n_items]\n",
    "        Training set\n",
    "    \n",
    "    test : scipy sparse csr_matrix, shape [n_users, n_items]\n",
    "        Test set\n",
    "    \"\"\"\n",
    "    assert test_size < 1.0 and test_size > 0.0\n",
    "\n",
    "    # Dictionary Of Keys based sparse matrix is more efficient\n",
    "    # for constructing sparse matrices incrementally compared with csr_matrix\n",
    "    train = ratings.copy().todok()\n",
    "    test = dok_matrix(train.shape)\n",
    "    \n",
    "    # for all the users assign randomly chosen interactions\n",
    "    # to the test and assign those interactions to zero in the training;\n",
    "    # when computing the interactions to go into the test set, \n",
    "    # remember to round up the numbers (e.g. a user has 4 ratings, if the\n",
    "    # test_size is 0.2, then 0.8 ratings will go to test, thus we need to\n",
    "    # round up to ensure the test set gets at least 1 rating)\n",
    "    rstate = np.random.RandomState(seed)\n",
    "    for u in range(ratings.shape[0]):\n",
    "        split_index = ratings[u].indices\n",
    "        n_splits = math.ceil(test_size * split_index.shape[0])\n",
    "        test_index = rstate.choice(split_index, size = n_splits, replace = False)\n",
    "        test[u, test_index] = ratings[u, test_index]\n",
    "        train[u, test_index] = 0\n",
    "    \n",
    "    train, test = train.tocsr(), test.tocsr()\n",
    "    return train, test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<786x726 sparse matrix of type '<class 'numpy.int64'>'\n",
       "\twith 171 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 134,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train, X_test = create_train_test(X, test_size = 0.2, seed = 1234)\n",
    "X_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 357,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BPR:\n",
    "    \"\"\"\n",
    "    Bayesian Personalized Ranking (BPR) for implicit feedback data\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    learning_rate : float, default 0.01\n",
    "        learning rate for gradient descent\n",
    "\n",
    "    n_factors : int, default 20\n",
    "        Number/dimension of user and item latent factors\n",
    "\n",
    "    n_iters : int, default 15\n",
    "        Number of iterations to train the algorithm\n",
    "        \n",
    "    batch_size : int, default 1000\n",
    "        batch size for batch gradient descent, the original paper\n",
    "        uses stochastic gradient descent (i.e., batch size of 1),\n",
    "        but this can make the training unstable (very sensitive to\n",
    "        learning rate)\n",
    "\n",
    "    reg : int, default 0.01\n",
    "        Regularization term for the user and item latent factors\n",
    "\n",
    "    seed : int, default 1234\n",
    "        Seed for the randomly initialized user, item latent factors\n",
    "\n",
    "    verbose : bool, default True\n",
    "        Whether to print progress bar while training\n",
    "\n",
    "    Attributes\n",
    "    ----------\n",
    "    user_factors : 2d ndarray, shape [n_users, n_factors]\n",
    "        User latent factors learnt\n",
    "\n",
    "    item_factors : 2d ndarray, shape [n_items, n_factors]\n",
    "        Item latent factors learnt\n",
    "\n",
    "    References\n",
    "    ----------\n",
    "    S. Rendle, C. Freudenthaler, Z. Gantner, L. Schmidt-Thieme \n",
    "    Bayesian Personalized Ranking from Implicit Feedback\n",
    "    - https://arxiv.org/abs/1205.2618\n",
    "    \"\"\"\n",
    "    def __init__(self, learning_rate = 0.01, n_factors = 15, n_iters = 10, \n",
    "                 batch_size = 1000, reg = 0.01, seed = 1234, verbose = True):\n",
    "        self.reg = reg\n",
    "        self.seed = seed\n",
    "        self.verbose = verbose\n",
    "        self.n_iters = n_iters\n",
    "        self.n_factors = n_factors\n",
    "        self.batch_size = batch_size\n",
    "        self.learning_rate = learning_rate\n",
    "        \n",
    "        # to avoid re-computation at predict\n",
    "        self._prediction = None\n",
    "        \n",
    "    def fit(self, ratings):\n",
    "        \"\"\"\n",
    "        Parameters\n",
    "        ----------\n",
    "        ratings : scipy sparse csr_matrix, shape [n_users, n_items]\n",
    "            sparse matrix of user-item interactions\n",
    "        \"\"\"\n",
    "        indptr = ratings.indptr\n",
    "        indices = ratings.indices\n",
    "        n_users, n_items = ratings.shape\n",
    "        \n",
    "        # ensure batch size makes sense, since the algorithm involves\n",
    "        # for each step randomly sample a user, thus the batch size\n",
    "        # should be smaller than the total number of users or else\n",
    "        # we would be sampling the user with replacement\n",
    "        batch_size = self.batch_size\n",
    "        if n_users < batch_size:\n",
    "            batch_size = n_users\n",
    "            sys.stderr.write('WARNING: Batch size is greater than number of users,'\n",
    "                             'switching to a batch size of {}\\n'.format(n_users))\n",
    "\n",
    "        batch_iters = n_users // batch_size\n",
    "        \n",
    "        # initialize random weights\n",
    "        rstate = np.random.RandomState(self.seed)\n",
    "        self.user_factors = rstate.normal(size = (n_users, self.n_factors))\n",
    "        self.item_factors = rstate.normal(size = (n_items, self.n_factors))\n",
    "        \n",
    "        # progress bar for training iteration if verbose is turned on\n",
    "        loop = range(self.n_iters)\n",
    "        if self.verbose:\n",
    "            loop = trange(self.n_iters, desc = self.__class__.__name__)\n",
    "        \n",
    "        for _ in loop:\n",
    "            for _ in range(batch_iters):\n",
    "                sampled = self._sample(n_users, n_items, indices, indptr)\n",
    "                sampled_users, sampled_pos_items, sampled_neg_items = sampled\n",
    "                self._update(sampled_users, sampled_pos_items, sampled_neg_items)\n",
    "\n",
    "        return self\n",
    "    \n",
    "    def _sample(self, n_users, n_items, indices, indptr):\n",
    "        \"\"\"sample batches of random triplets u, i, j\"\"\"\n",
    "        sampled_pos_items = np.zeros(self.batch_size, dtype = np.int)\n",
    "        sampled_neg_items = np.zeros(self.batch_size, dtype = np.int)\n",
    "        sampled_users = np.random.choice(\n",
    "            n_users, size = self.batch_size, replace = False)\n",
    "\n",
    "        for idx, user in enumerate(sampled_users):\n",
    "            if len(indices[indptr[user]:indptr[user + 1]]) > 0:\n",
    "                \n",
    "                pos_items = indices[indptr[user]:indptr[user + 1]]\n",
    "#                 print(\"33pos_items:\", pos_items)\n",
    "                pos_item = np.random.choice(pos_items)\n",
    "                neg_item = np.random.choice(n_items)\n",
    "                while neg_item in pos_items:\n",
    "                    neg_item = np.random.choice(n_items)\n",
    "\n",
    "                sampled_pos_items[idx] = pos_item\n",
    "                sampled_neg_items[idx] = neg_item\n",
    "#                 print(sampled_pos_items, sampled_neg_items)\n",
    "\n",
    "        return sampled_users, sampled_pos_items, sampled_neg_items\n",
    "                \n",
    "    def _update(self, u, i, j):\n",
    "        \"\"\"\n",
    "        update according to the bootstrapped user u, \n",
    "        positive item i and negative item j\n",
    "        \"\"\"\n",
    "        user_u = self.user_factors[u]\n",
    "        item_i = self.item_factors[i]\n",
    "        item_j = self.item_factors[j]\n",
    "        \n",
    "        # decompose the estimator, compute the difference between\n",
    "        # the score of the positive items and negative items; a\n",
    "        # naive implementation might look like the following:\n",
    "        # r_ui = np.diag(user_u.dot(item_i.T))\n",
    "        # r_uj = np.diag(user_u.dot(item_j.T))\n",
    "        # r_uij = r_ui - r_uj\n",
    "        \n",
    "        # however, we can do better, so\n",
    "        # for batch dot product, instead of doing the dot product\n",
    "        # then only extract the diagonal element (which is the value\n",
    "        # of that current batch), we perform a hadamard product, \n",
    "        # i.e. matrix element-wise product then do a sum along the column will\n",
    "        # be more efficient since it's less operations\n",
    "        # http://people.revoledu.com/kardi/tutorial/LinearAlgebra/HadamardProduct.html\n",
    "        # r_ui = np.sum(user_u * item_i, axis = 1)\n",
    "        #\n",
    "        # then we can achieve another speedup by doing the difference\n",
    "        # on the positive and negative item up front instead of computing\n",
    "        # r_ui and r_uj separately, these two idea will speed up the operations\n",
    "        # from 1:14 down to 0.36\n",
    "        r_uij = np.sum(user_u * (item_i - item_j), axis = 1)\n",
    "        sigmoid = np.exp(-r_uij) / (1.0 + np.exp(-r_uij))\n",
    "        \n",
    "        # repeat the 1 dimension sigmoid n_factors times so\n",
    "        # the dimension will match when doing the update\n",
    "        sigmoid_tiled = np.tile(sigmoid, (self.n_factors, 1)).T\n",
    "\n",
    "        # update using gradient descent\n",
    "        grad_u = sigmoid_tiled * (item_j - item_i) + self.reg * user_u\n",
    "        grad_i = sigmoid_tiled * -user_u + self.reg * item_i\n",
    "        grad_j = sigmoid_tiled * user_u + self.reg * item_j\n",
    "        self.user_factors[u] -= self.learning_rate * grad_u\n",
    "        self.item_factors[i] -= self.learning_rate * grad_i\n",
    "        self.item_factors[j] -= self.learning_rate * grad_j\n",
    "        return self\n",
    "\n",
    "    def predict(self):\n",
    "        \"\"\"\n",
    "        Obtain the predicted ratings for every users and items\n",
    "        by doing a dot product of the learnt user and item vectors.\n",
    "        The result will be cached to avoid re-computing it every time\n",
    "        we call predict, thus there will only be an overhead the first\n",
    "        time we call it. Note, ideally you probably don't need to compute\n",
    "        this as it returns a dense matrix and may take up huge amounts of\n",
    "        memory for large datasets\n",
    "        \"\"\"\n",
    "        if self._prediction is None:\n",
    "            self._prediction = self.user_factors.dot(self.item_factors.T)\n",
    "\n",
    "        return self._prediction\n",
    "\n",
    "    def _predict_user(self, user):\n",
    "        \"\"\"\n",
    "        returns the predicted ratings for the specified user,\n",
    "        this is mainly used in computing evaluation metric\n",
    "        \"\"\"\n",
    "        user_pred = self.user_factors[user].dot(self.item_factors.T)\n",
    "        return user_pred\n",
    "\n",
    "    def recommend(self, ratings, N = 1000):\n",
    "        \"\"\"\n",
    "        Returns the top N ranked items for given user id,\n",
    "        excluding the ones that the user already liked\n",
    "        \n",
    "        Parameters\n",
    "        ----------\n",
    "        ratings : scipy sparse csr_matrix, shape [n_users, n_items]\n",
    "            sparse matrix of user-item interactions \n",
    "        \n",
    "        N : int, default 5\n",
    "            top-N similar items' N\n",
    "        \n",
    "        Returns\n",
    "        -------\n",
    "        recommendation : 2d ndarray, shape [number of users, N]\n",
    "            each row is the top-N ranked item for each query user\n",
    "        \"\"\"\n",
    "        n_users = ratings.shape[0]\n",
    "        recommendation = np.zeros((n_users, N), dtype = np.uint32)\n",
    "        for user in range(n_users):\n",
    "            top_n = self._recommend_user(ratings, user, N)\n",
    "            recommendation[user] = top_n\n",
    "\n",
    "        return recommendation\n",
    "\n",
    "    def _recommend_user(self, ratings, user, N):\n",
    "        \"\"\"the top-N ranked items for a given user\"\"\"\n",
    "        scores = self._predict_user(user)\n",
    "        print(\"**scores:\", scores)\n",
    "        \n",
    "\n",
    "        # compute the top N items, removing the items that the user already liked\n",
    "        # from the result and ensure that we don't get out of bounds error when \n",
    "        # we ask for more recommendations than that are available\n",
    "        liked = set(ratings[user].indices)\n",
    "        count = N + len(liked)\n",
    "        if count < scores.shape[0]:\n",
    "\n",
    "            # when trying to obtain the top-N indices from the score,\n",
    "            # using argpartition to retrieve the top-N indices in \n",
    "            # unsorted order and then sort them will be faster than doing\n",
    "            # straight up argort on the entire score\n",
    "            # http://stackoverflow.com/questions/42184499/cannot-understand-numpy-argpartition-output\n",
    "            ids = np.argpartition(scores, -count)[-count:]\n",
    "            best_ids = np.argsort(scores[ids])[::-1]\n",
    "            best = ids[best_ids]\n",
    "        else:\n",
    "            best = np.argsort(scores)[::-1]\n",
    "\n",
    "        top_n = list(islice((rec for rec in best if rec not in liked), N))\n",
    "        return top_n\n",
    "    \n",
    "    def get_similar_items(self, N = 5, item_ids = None):\n",
    "        \n",
    "        \"\"\"\n",
    "        return the top N similar items for itemid, where\n",
    "        cosine distance is used as the distance metric\n",
    "        \n",
    "        Parameters\n",
    "        ----------\n",
    "        N : int, default 5\n",
    "            top-N similar items' N\n",
    "            \n",
    "        item_ids : 1d iterator, e.g. list or numpy array, default None\n",
    "            the item ids that we wish to find the similar items\n",
    "            of, the default None will compute the similar items\n",
    "            for all the items\n",
    "        \n",
    "        Returns\n",
    "        -------\n",
    "        similar_items : 2d ndarray, shape [number of query item_ids, N]\n",
    "            each row is the top-N most similar item id for each\n",
    "            query item id\n",
    "        \"\"\"\n",
    "        # cosine distance is proportional to normalized euclidean distance,\n",
    "        # thus we normalize the item vectors and use euclidean metric so\n",
    "        # we can use the more efficient kd-tree for nearest neighbor search;\n",
    "        # also the item will always to nearest to itself, so we add 1 to \n",
    "        # get an additional nearest item and remove itself at the end\n",
    "        normed_factors = preprocessing.normalize(self.item_factors)\n",
    "        knn = NearestNeighbors(n_neighbors = N + 1, metric = 'euclidean')\n",
    "#         .fit(X)\n",
    "\n",
    "        # returns a distance, index tuple,\n",
    "        # we don't actually need the distance\n",
    "        if item_ids is not None:\n",
    "            normed_factors = normed_factors[item_ids]\n",
    "\n",
    "        _, items = knn.kneighbors(normed_factors)\n",
    "#         dist, items = knn.kneighbors(normed_factors, return_distance=True)\n",
    "#         print(items)\n",
    "       \n",
    "        similar_items = items[:, 1:].astype(np.uint32)\n",
    "      \n",
    "        return similar_items"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 358,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "BPR: 100%|██████████| 10/10 [00:00<00:00, 172.40it/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<__main__.BPR at 0x18ba399e9d0>"
      ]
     },
     "execution_count": 358,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# parameters were randomly chosen\n",
    "bpr_params = {'reg': 0.01,\n",
    "              'learning_rate': 0.1,\n",
    "              'n_iters': 10,\n",
    "              'n_factors': 30,\n",
    "              'batch_size': 150}\n",
    "\n",
    "bpr = BPR(**bpr_params)\n",
    "bpr.fit(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 359,
   "metadata": {},
   "outputs": [
    {
     "ename": "NotFittedError",
     "evalue": "This NearestNeighbors instance is not fitted yet. Call 'fit' with appropriate arguments before using this estimator.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNotFittedError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-359-4a9e12a188a4>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mbpr\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_similar_items\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mN\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m2\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m<ipython-input-357-4df1dcc87040>\u001b[0m in \u001b[0;36mget_similar_items\u001b[1;34m(self, N, item_ids)\u001b[0m\n\u001b[0;32m    277\u001b[0m             \u001b[0mnormed_factors\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnormed_factors\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mitem_ids\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    278\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 279\u001b[1;33m         \u001b[0m_\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mitems\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mknn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mkneighbors\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnormed_factors\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    280\u001b[0m \u001b[1;31m#         dist, items = knn.kneighbors(normed_factors, return_distance=True)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    281\u001b[0m \u001b[1;31m#         print(items)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\sklearn\\neighbors\\_base.py\u001b[0m in \u001b[0;36mkneighbors\u001b[1;34m(self, X, n_neighbors, return_distance)\u001b[0m\n\u001b[0;32m    583\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    584\u001b[0m         \"\"\"\n\u001b[1;32m--> 585\u001b[1;33m         \u001b[0mcheck_is_fitted\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    586\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    587\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mn_neighbors\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\u001b[0m in \u001b[0;36minner_f\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     70\u001b[0m                           FutureWarning)\n\u001b[0;32m     71\u001b[0m         \u001b[0mkwargs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m{\u001b[0m\u001b[0mk\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0marg\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mk\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0marg\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msig\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mparameters\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 72\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     73\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0minner_f\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     74\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\u001b[0m in \u001b[0;36mcheck_is_fitted\u001b[1;34m(estimator, attributes, msg, all_or_any)\u001b[0m\n\u001b[0;32m   1017\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1018\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mattrs\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1019\u001b[1;33m         \u001b[1;32mraise\u001b[0m \u001b[0mNotFittedError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmsg\u001b[0m \u001b[1;33m%\u001b[0m \u001b[1;33m{\u001b[0m\u001b[1;34m'name'\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mtype\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mestimator\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__name__\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1020\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1021\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNotFittedError\u001b[0m: This NearestNeighbors instance is not fitted yet. Call 'fit' with appropriate arguments before using this estimator."
     ]
    }
   ],
   "source": [
    "bpr.get_similar_items(N = 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 349,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def auc_score(model, ratings):\n",
    "#     \"\"\"\n",
    "#     computes area under the ROC curve (AUC).\n",
    "#     The full name should probably be mean\n",
    "#     auc score as it is computing the auc\n",
    "#     for every user's prediction and actual\n",
    "#     interaction and taking the average for\n",
    "#     all users\n",
    "    \n",
    "#     Parameters\n",
    "#     ----------\n",
    "#     model : BPR instance\n",
    "#         Trained BPR model\n",
    "        \n",
    "#     ratings : scipy sparse csr_matrix, shape [n_users, n_items]\n",
    "#         sparse matrix of user-item interactions\n",
    "    \n",
    "#     Returns\n",
    "#     -------\n",
    "#     auc : float 0.0 ~ 1.0\n",
    "#     \"\"\"\n",
    "#     auc = 0.0\n",
    "#     n_users, n_items = ratings.shape\n",
    "#     for user, row in enumerate(ratings):\n",
    "#         y_pred = model._predict_user(user)\n",
    "#         y_true = np.zeros(n_items)\n",
    "#         y_true[row.indices] = 1\n",
    "#         auc += roc_auc_score(y_true, y_pred)\n",
    "\n",
    "#     auc /= n_users\n",
    "#     return auc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 350,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(auc_score(bpr, X_train))\n",
    "# print(auc_score(bpr, X_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
